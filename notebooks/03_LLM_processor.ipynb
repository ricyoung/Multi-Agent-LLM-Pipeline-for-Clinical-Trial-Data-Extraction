{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import openai\n",
    "import requests\n",
    "import pandas as pd\n",
    "import openai\n",
    "import json\n",
    "\n",
    "import logging\n",
    "import time\n",
    "\n",
    "from typing import List, Dict, Any, Optional\n",
    "from enum import Enum\n",
    "from dataclasses import dataclass\n",
    "\n",
    "import openrouter\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the openrouter module\n",
    "\n",
    "\n",
    "# Set the API key\n",
    "# openrouter.api_key = os.getenv(\"OPENROUTER_API_KEY\")\n",
    "\n",
    "openrouter.api_key = os.getenv(\"OPENROUTER_API_KEY\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disease = 'Aging'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define file path\n",
    "# file_path_parquet = os.path.join('02_data_processed', '02_covariates_filtered.parquet')\n",
    "\n",
    "file_path_parquet = os.path.join('02_filtered_data', '02_simple_filter.parquet')\n",
    "\n",
    "# Load the DataFrame from the Parquet file\n",
    "filtered_df_covariates = pd.read_parquet(file_path_parquet)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(filtered_df_covariates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(filtered_df_covariates.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import json\n",
    "import logging\n",
    "import pandas as pd\n",
    "import time\n",
    "from typing import Dict, List, Optional\n",
    "from dataclasses import dataclass\n",
    "from enum import Enum\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    datefmt='%Y-%m-%d %H:%M:%S'\n",
    ")\n",
    "\n",
    "class APIError(Exception):\n",
    "    \"\"\"Custom exception for API-related errors\"\"\"\n",
    "    pass\n",
    "\n",
    "class ValidationError(Exception):\n",
    "    \"\"\"Custom exception for response validation errors\"\"\"\n",
    "    pass\n",
    "\n",
    "class BrainStimStatus(str, Enum):\n",
    "    YES = \"Yes\"\n",
    "    NO = \"No\"\n",
    "\n",
    "@dataclass\n",
    "class StimulationParameters:\n",
    "    frequency: Optional[str] = None\n",
    "    intensity: Optional[str] = None\n",
    "    duration: Optional[str] = None\n",
    "\n",
    "@dataclass\n",
    "class StimulationDetails:\n",
    "    primary_type: Optional[str] = None\n",
    "    is_noninvasive: Optional[bool] = None\n",
    "    primary_target: Optional[str] = None\n",
    "    secondary_targets: List[str] = None\n",
    "    stimulation_parameters: StimulationParameters = None\n",
    "\n",
    "    def __post_init__(self):\n",
    "        if self.secondary_targets is None:\n",
    "            self.secondary_targets = []\n",
    "        if self.stimulation_parameters is None:\n",
    "            self.stimulation_parameters = StimulationParameters()\n",
    "\n",
    "@dataclass\n",
    "class BrainStimResponse:\n",
    "    brain_stimulation_used: BrainStimStatus\n",
    "    stimulation_details: StimulationDetails\n",
    "    confidence_level: str\n",
    "    relevant_quotes: List[str]\n",
    "\n",
    "class BrainStimAnalyzer:\n",
    "    def __init__(self, api_key: str, site_url: str, app_name: str):\n",
    "        self.api_key = openrouter.api_key \n",
    "        self.site_url = site_url\n",
    "        self.app_name = app_name\n",
    "        \n",
    "        # You can replace or update these models as desired\n",
    "        self.models = {\n",
    "            \"openai/o1-mini\": {\n",
    "                \"max_tokens\": 120000,  # manually lowered from 128000\n",
    "                \"temperature\": 0.5,\n",
    "                \"instructions\": \"Return ONLY a JSON object with no additional explanatory text.\",\n",
    "                \"type\": \"openai_like\"\n",
    "            },\n",
    "            \"x-ai/grok-2-1212\": {\n",
    "                \"max_tokens\": 120000,\n",
    "                \"temperature\": 0.5,\n",
    "                \"instructions\": \"Return ONLY a JSON object with no additional explanatory text.\",\n",
    "                \"type\": \"openai_like\"\n",
    "            },\n",
    "            \"meta-llama/llama-3.3-70b-instruct\": {\n",
    "                \"max_tokens\": 120000,\n",
    "                \"temperature\": 0.5,\n",
    "                \"instructions\": \"Return ONLY a JSON object with no additional explanatory text.\",\n",
    "                \"type\": \"openai_like\"  # or \"llama_like\" if needed\n",
    "            },\n",
    "            # === Add the new models here ===\n",
    "            \"google/gemini-flash-1.5-8b\": {\n",
    "                \"max_tokens\": 120000,\n",
    "                \"temperature\": 0.5,\n",
    "                \"instructions\": \"Return ONLY a JSON object with no additional explanatory text.\",\n",
    "                \"type\": \"openai_like\"  # or another type as required by your usage\n",
    "            },\n",
    "            \"deepseek/deepseek-r1-distill-llama-70b\": {\n",
    "                \"max_tokens\": 120000,\n",
    "                \"temperature\": 0.5,\n",
    "                \"instructions\": \"Return ONLY a JSON object with no additional explanatory text.\",\n",
    "                \"type\": \"openai_like\"\n",
    "            }\n",
    "        }\n",
    "\n",
    "    def extract_json_from_text(self, text: str) -> Optional[str]:\n",
    "        \"\"\"\n",
    "        Attempt to extract a JSON substring from a block of text.\n",
    "        Return None if not valid JSON or cannot find curly braces.\n",
    "        \"\"\"\n",
    "        if not text or not isinstance(text, str):\n",
    "            return None\n",
    "\n",
    "        try:\n",
    "            start = text.find('{')\n",
    "            end = text.rfind('}')\n",
    "            if start != -1 and end != -1:\n",
    "                json_str = text[start:end+1]\n",
    "                # Validate it's proper JSON\n",
    "                json.loads(json_str)\n",
    "                return json_str\n",
    "        except json.JSONDecodeError:\n",
    "            pass\n",
    "        return None\n",
    "\n",
    "    def validate_brain_stim_response(self, response_json: Dict) -> BrainStimResponse:\n",
    "        \"\"\"Validate response structure and content, handling any None fields gracefully.\"\"\"\n",
    "        required_fields = [\n",
    "            \"brain_stimulation_used\",\n",
    "            \"stimulation_details\",\n",
    "            \"confidence_level\",\n",
    "            \"relevant_quotes\"\n",
    "        ]\n",
    "\n",
    "        for field in required_fields:\n",
    "            if field not in response_json:\n",
    "                raise ValidationError(f\"Missing required field: {field}\")\n",
    "\n",
    "        # Validate brain_stimulation_used\n",
    "        if not isinstance(response_json[\"brain_stimulation_used\"], str):\n",
    "            raise ValidationError(\"brain_stimulation_used must be string\")\n",
    "        if response_json[\"brain_stimulation_used\"] not in [\"Yes\", \"No\"]:\n",
    "            raise ValidationError(\"brain_stimulation_used must be 'Yes' or 'No'\")\n",
    "\n",
    "        # Safely handle any missing or null \"stimulation_details\"\n",
    "        stim_details_data = response_json.get(\"stimulation_details\") or {}\n",
    "        # Safely handle any missing or null \"stimulation_parameters\"\n",
    "        stim_params_data = stim_details_data.get(\"stimulation_parameters\") or {}\n",
    "\n",
    "        # Build StimulationParameters object\n",
    "        stim_params = StimulationParameters(**stim_params_data)\n",
    "\n",
    "        # Build StimulationDetails object\n",
    "        stim_details = StimulationDetails(\n",
    "            primary_type=stim_details_data.get(\"primary_type\"),\n",
    "            is_noninvasive=stim_details_data.get(\"is_noninvasive\"),\n",
    "            primary_target=stim_details_data.get(\"primary_target\"),\n",
    "            secondary_targets=stim_details_data.get(\"secondary_targets\"),\n",
    "            stimulation_parameters=stim_params\n",
    "        )\n",
    "\n",
    "        # Make sure relevant_quotes is a list\n",
    "        relevant_quotes = response_json.get(\"relevant_quotes\")\n",
    "        if not isinstance(relevant_quotes, list):\n",
    "            relevant_quotes = []\n",
    "\n",
    "        return BrainStimResponse(\n",
    "            brain_stimulation_used=BrainStimStatus(response_json[\"brain_stimulation_used\"]),\n",
    "            stimulation_details=stim_details,\n",
    "            confidence_level=response_json[\"confidence_level\"],\n",
    "            relevant_quotes=relevant_quotes\n",
    "        )\n",
    "\n",
    "    def send_request(self, model_name: str, prompt: str, max_retries: int = 3) -> Optional[BrainStimResponse]:\n",
    "        \"\"\"\n",
    "        Send request to OpenRouter with retry logic.\n",
    "        Returns a BrainStimResponse or None if there's an error or invalid response.\n",
    "        \"\"\"\n",
    "        if model_name not in self.models:\n",
    "            raise ValueError(f\"Unknown model: {model_name}\")\n",
    "\n",
    "        model_config = self.models[model_name]\n",
    "\n",
    "        # We'll attach our special instructions plus the user prompt\n",
    "        final_prompt = f\"{model_config['instructions']}\\n{prompt}\"\n",
    "\n",
    "        json_body = {\n",
    "            \"model\": model_name,\n",
    "            \"temperature\": model_config[\"temperature\"],\n",
    "            \"max_tokens\": model_config[\"max_tokens\"],\n",
    "            # OpenAI-like messages\n",
    "            \"messages\": [{\"role\": \"user\", \"content\": final_prompt}]\n",
    "        }\n",
    "\n",
    "        retries = 0\n",
    "        backoff = 2  # seconds\n",
    "\n",
    "        while retries < max_retries:\n",
    "            try:\n",
    "                response = requests.post(\n",
    "                    url=\"https://openrouter.ai/api/v1/chat/completions\",\n",
    "                    headers={\n",
    "                        \"Authorization\": f\"Bearer {self.api_key}\",\n",
    "                        \"HTTP-Referer\": self.site_url,\n",
    "                        \"X-Title\": self.app_name,\n",
    "                        \"Content-Type\": \"application/json\"\n",
    "                    },\n",
    "                    data=json.dumps(json_body),\n",
    "                    timeout=60\n",
    "                )\n",
    "                logging.info(f\"Sent request to {model_name}\")\n",
    "                logging.debug(f\"Raw response text: {response.text}\")\n",
    "\n",
    "                # Attempt to parse the top-level JSON\n",
    "                try:\n",
    "                    response_data = response.json()\n",
    "                except json.JSONDecodeError:\n",
    "                    logging.error(f\"Response from {model_name} is not valid JSON: {response.text}\")\n",
    "                    return None\n",
    "\n",
    "                # Check if top-level JSON indicates an error\n",
    "                if \"error\" in response_data:\n",
    "                    logging.error(f\"Model {model_name} returned an error: {response_data['error']}\")\n",
    "                    return None\n",
    "\n",
    "                # Now handle different status codes\n",
    "                if response.status_code == 200:\n",
    "                    # For an OpenAI-like response, read from \"choices\"\n",
    "                    choices = response_data.get(\"choices\", [])\n",
    "                    if not choices:\n",
    "                        logging.error(\"Response does not contain 'choices' or it's empty.\")\n",
    "                        return None\n",
    "\n",
    "                    choice = choices[0]\n",
    "                    message_obj = choice.get(\"message\")\n",
    "                    if not message_obj or \"content\" not in message_obj:\n",
    "                        logging.error(\"Response does not contain 'message' or 'content' keys.\")\n",
    "                        return None\n",
    "\n",
    "                    content = message_obj[\"content\"]\n",
    "                    # Safely handle None or empty content\n",
    "                    if not content or not isinstance(content, str):\n",
    "                        logging.error(\"Content is empty or not a string.\")\n",
    "                        return None\n",
    "\n",
    "                    content = content.strip()\n",
    "                    # Attempt to parse the content as JSON\n",
    "                    try:\n",
    "                        response_json = json.loads(content)\n",
    "                    except json.JSONDecodeError:\n",
    "                        # Try to extract JSON substring if the response has extra text\n",
    "                        json_str = self.extract_json_from_text(content)\n",
    "                        if not json_str:\n",
    "                            logging.error(f\"Could not extract valid JSON from response: {content}\")\n",
    "                            return None\n",
    "                        try:\n",
    "                            response_json = json.loads(json_str)\n",
    "                        except json.JSONDecodeError:\n",
    "                            logging.error(f\"Could not parse JSON substring from response: {content}\")\n",
    "                            return None\n",
    "\n",
    "                    # Validate final JSON structure\n",
    "                    try:\n",
    "                        return self.validate_brain_stim_response(response_json)\n",
    "                    except ValidationError as ve:\n",
    "                        logging.error(f\"Validation Error: {str(ve)}\")\n",
    "                        return None\n",
    "\n",
    "                elif response.status_code in [429, 500, 502, 503, 504]:\n",
    "                    # Retry for these statuses\n",
    "                    if retries == max_retries - 1:\n",
    "                        logging.error(f\"Max retries reached for {model_name} with status {response.status_code}\")\n",
    "                        return None\n",
    "                    retries += 1\n",
    "                    time.sleep(backoff)\n",
    "                    backoff *= 2\n",
    "                    continue\n",
    "                else:\n",
    "                    # Other statuses: treat as non-retryable\n",
    "                    logging.error(f\"Request failed with status {response.status_code}: {response.text}\")\n",
    "                    return None\n",
    "\n",
    "            except requests.exceptions.RequestException as e:\n",
    "                # This covers any network issues, timeouts, etc.\n",
    "                logging.error(f\"Request to {model_name} failed: {e}\")\n",
    "                if retries == max_retries - 1:\n",
    "                    return None\n",
    "                retries += 1\n",
    "                time.sleep(backoff)\n",
    "                backoff *= 2\n",
    "                continue\n",
    "\n",
    "        return None\n",
    "\n",
    "class BrainStimAnalysis:\n",
    "    def __init__(self, api_key: str, site_url: str, app_name: str):\n",
    "        self.analyzer = BrainStimAnalyzer(api_key, site_url, app_name)\n",
    "\n",
    "    def process_trial(self, df: pd.DataFrame, output_dir: str = '03_data_ai'):\n",
    "        \"\"\"Process trial data and save results.\"\"\"\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        result_df = df.copy()\n",
    "\n",
    "        # Initialize response arrays\n",
    "        responses = []\n",
    "        \n",
    "        # Process each row\n",
    "        for idx, row in df.iterrows():\n",
    "            # Combine your instructions with the row text\n",
    "            context = row.get('DetailedDescription') or row.get('BriefSummary') or \"\"\n",
    "            prompt = self.generate_prompt(context)\n",
    "\n",
    "            # For each model in the dictionary\n",
    "            for model_name in self.analyzer.models.keys():\n",
    "                response = self.analyzer.send_request(model_name, prompt)\n",
    "                if response is None:\n",
    "                    logging.error(f\"Error processing row {idx} with model {model_name}.\")\n",
    "                    # Skip this model and continue to the next\n",
    "                    continue\n",
    "\n",
    "                # Store the valid response\n",
    "                responses.append({\"Model\": model_name, \"Response\": response})\n",
    "                \n",
    "                # Update DataFrame with response data\n",
    "                self.update_dataframe(result_df, idx, model_name, response)\n",
    "\n",
    "        # Save results\n",
    "        self.save_results(result_df, output_dir)\n",
    "        return result_df, responses\n",
    "\n",
    "    def generate_prompt(self, context: str) -> str:\n",
    "        \"\"\"Generate analysis prompt from context.\"\"\"\n",
    "        return f\"\"\"\n",
    "        Analyze whether brain stimulation was used in this trial. If so, provide details.\n",
    "\n",
    "        IMPORTANT: Respond ONLY with a JSON object in the EXACT format below. Do not include any additional text or explanations.\n",
    "\n",
    "        {{\n",
    "            \"brain_stimulation_used\": \"Yes\" or \"No\",\n",
    "            \"stimulation_details\": {{\n",
    "                \"primary_type\": \"e.g., tDCS, TMS, tACS, DBS, etc.\" or null,\n",
    "                \"is_noninvasive\": true or false,\n",
    "                \"primary_target\": \"Primary brain region or null\",\n",
    "                \"secondary_targets\": [\"List of secondary regions\"] or [],\n",
    "                \"stimulation_parameters\": {{\n",
    "                    \"frequency\": \"e.g., 10Hz\" or null,\n",
    "                    \"intensity\": \"e.g., 2mA\" or null,\n",
    "                    \"duration\": \"e.g., 20 minutes\" or null\n",
    "                }}\n",
    "            }},\n",
    "            \"confidence_level\": \"High\", \"Medium\", or \"Low\",\n",
    "            \"relevant_quotes\": [\"Direct quotes supporting the analysis\"]\n",
    "        }}\n",
    "\n",
    "        Context:\n",
    "        {context}\n",
    "        \"\"\"\n",
    "\n",
    "    def update_dataframe(self, df: pd.DataFrame, idx: int, model_name: str, response: BrainStimResponse):\n",
    "        \"\"\"Update DataFrame with response data.\"\"\"\n",
    "        suffix = model_name.replace(\"/\", \"_\").replace(\"-\", \"_\")\n",
    "        \n",
    "        # Update brain stimulation status\n",
    "        df.at[idx, f\"brain_stimulation_used_{suffix}\"] = response.brain_stimulation_used.value\n",
    "        \n",
    "        # Update stimulation details\n",
    "        if response.stimulation_details:\n",
    "            df.at[idx, f\"stimulation_details_primary_type_{suffix}\"] = response.stimulation_details.primary_type\n",
    "            df.at[idx, f\"stimulation_details_is_noninvasive_{suffix}\"] = response.stimulation_details.is_noninvasive\n",
    "            df.at[idx, f\"stimulation_details_primary_target_{suffix}\"] = response.stimulation_details.primary_target\n",
    "            df.at[idx, f\"stimulation_details_secondary_targets_{suffix}\"] = json.dumps(response.stimulation_details.secondary_targets)\n",
    "            \n",
    "            # Update parameters\n",
    "            params = response.stimulation_details.stimulation_parameters\n",
    "            df.at[idx, f\"stimulation_details_parameters_frequency_{suffix}\"] = params.frequency\n",
    "            df.at[idx, f\"stimulation_details_parameters_intensity_{suffix}\"] = params.intensity\n",
    "            df.at[idx, f\"stimulation_details_parameters_duration_{suffix}\"] = params.duration\n",
    "        \n",
    "        # Update confidence and quotes\n",
    "        df.at[idx, f\"confidence_level_{suffix}\"] = response.confidence_level\n",
    "        df.at[idx, f\"relevant_quotes_{suffix}\"] = json.dumps(response.relevant_quotes)\n",
    "\n",
    "    def save_results(self, df: pd.DataFrame, output_dir: str):\n",
    "        \"\"\"Save results to files.\"\"\"\n",
    "        df.to_excel(f'{output_dir}/part_3_covariates_done.xlsx', index=False)\n",
    "        df.to_parquet(f'{output_dir}/part_3_covariates_done.parquet', index=False)\n",
    "\n",
    "def main():\n",
    "    # Example config - use your actual approach to load the API key\n",
    "    api_key = os.getenv(\"OPENROUTER_API_KEY\")\n",
    "    site_url = 'https://Aged-Research.com'\n",
    "    app_name = 'Aged + NIBS'\n",
    "\n",
    "    if not api_key:\n",
    "        logging.error(\"API_KEY is not set. Please set the OPENROUTER_API_KEY environment variable.\")\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        # Load your DataFrame however you do (Excel, CSV, etc.)\n",
    "        # df = pd.read_excel('filtered_df_covariates.xlsx')\n",
    "        df = filtered_df_covariates  # Replace with your real DataFrame variable\n",
    "        df = df.reset_index(drop=True)\n",
    "\n",
    "        # Run analysis\n",
    "        analysis = BrainStimAnalysis(api_key, site_url, app_name)\n",
    "        result_df, responses = analysis.process_trial(df)\n",
    "\n",
    "        # Save additional outputs\n",
    "        output_dir = '03_data_ai'\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "        result_df.to_excel(f'{output_dir}/part_3_covariates_done_v2.xlsx', index=False)\n",
    "        result_df.to_parquet(f'{output_dir}/part_3_covariates_done_v2.parquet', index=False)\n",
    "\n",
    "        # Convert responses to DataFrame and save\n",
    "        responses_df = pd.DataFrame([\n",
    "            {\n",
    "                \"Model\": r[\"Model\"],\n",
    "                \"BrainStimulationUsed\": r[\"Response\"].brain_stimulation_used.value,\n",
    "                \"PrimaryType\": r[\"Response\"].stimulation_details.primary_type,\n",
    "                \"ConfidenceLevel\": r[\"Response\"].confidence_level,\n",
    "                \"Quotes\": r[\"Response\"].relevant_quotes\n",
    "            }\n",
    "            for r in responses\n",
    "        ])\n",
    "        responses_df.to_excel(f'{output_dir}/responses_done_v2.xlsx', index=False)\n",
    "        responses_df.to_parquet(f'{output_dir}/responses_done_v2.parquet', index=False)\n",
    "\n",
    "        logging.info(\"All results saved successfully.\")\n",
    "\n",
    "        # Optional: Display results\n",
    "        print(\"\\n=== Updated LLM Responses ===\")\n",
    "        print(result_df)\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error in main execution: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "\n",
    "\n",
    "resp = requests.post('https://textbelt.com/text', {\n",
    "\n",
    "  'phone': '9163802941',\n",
    "\n",
    "  'message': 'PD Pipe Line Part 3 Done',\n",
    "\n",
    "  'key': '138adc496234ca311154757db147f552afa8ba83FfrCKJ36kTJNXq65nlsvvF4Pu',\n",
    "\n",
    "})\n",
    "\n",
    "print(resp.json())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PD_research_2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}